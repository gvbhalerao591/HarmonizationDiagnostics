from DiagnoseHarmonization import DiagnosticFunctions

import numpy as np

group1 = np.array([1,2,3,4,5])
group2 = np.array([2,3,4,5,6])

def test_cohens_d():
    assert DiagnosticFunctions.Cohens_D(group1, group2) == [0, 0, 0, 0, 0]

def test_pca_corr():
    # Create a sample dataset
    np.random.seed(0)
    X = np.random.rand(100, 5)  # 100 samples, 3 features
    batch = np.random.rand(100)  # Batch variable

    # Call the PCA correlation function
    pearsonr, explained_variance, score, batchPCcorr = DiagnosticFunctions.PcaCorr(X, batch)

    # Check the shape of the results
    assert score.shape == (100, 3)  # Score should have the same number of samples as X
    assert len(explained_variance) == 3  # Explained variance should match number of features
    assert len(batchPCcorr) == 3  # We only compute correlation for the first 3 PCs


def test_mahalanobis_distance():
# Create a sample dataset

    np.random.seed(0)
    Data = np.random.rand(100, 5)  # 100 samples, 5 features
    batch = np.random.randint(0, 3, size=100)  # 3 unique batches

    # Call the Mahalanobis distance function
    distance = DiagnosticFunctions.MahalanobisDistance(Data, batch)
    print(distance)

    # Check the type of the result
    assert isinstance(distance, dict)

    # Check that we have distances for each pair of batches
    unique_batches = np.unique(batch)
    assert len(distance) == len(unique_batches) * (len(unique_batches) - 1) / 2

    # Check that distances are non-negative
    for key in distance:
        assert distance[key] >= 0
        